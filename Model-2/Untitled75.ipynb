{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "vw9Z2ytSyxkJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "_004wjuW05fb"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/content/dengue_features_train_with_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "WQ_9sBC-1Cl_",
    "outputId": "53d82b28-d7a6-482f-d263-7e6562e0a1c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.57</td>\n",
       "      <td>297.74</td>\n",
       "      <td>292.41</td>\n",
       "      <td>299.8</td>\n",
       "      <td>295.9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>73.37</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2.63</td>\n",
       "      <td>25.44</td>\n",
       "      <td>6.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>1990-05-07</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.21</td>\n",
       "      <td>298.44</td>\n",
       "      <td>293.95</td>\n",
       "      <td>300.9</td>\n",
       "      <td>296.4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>77.37</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.37</td>\n",
       "      <td>2.37</td>\n",
       "      <td>26.71</td>\n",
       "      <td>6.37</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>1990-05-14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.78</td>\n",
       "      <td>298.88</td>\n",
       "      <td>295.43</td>\n",
       "      <td>300.5</td>\n",
       "      <td>297.3</td>\n",
       "      <td>26.10</td>\n",
       "      <td>82.05</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.85</td>\n",
       "      <td>2.30</td>\n",
       "      <td>26.71</td>\n",
       "      <td>6.49</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>1990-05-21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.99</td>\n",
       "      <td>299.23</td>\n",
       "      <td>295.31</td>\n",
       "      <td>301.4</td>\n",
       "      <td>297.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.34</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.67</td>\n",
       "      <td>2.43</td>\n",
       "      <td>27.47</td>\n",
       "      <td>6.77</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>1990-05-28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.52</td>\n",
       "      <td>299.66</td>\n",
       "      <td>295.82</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.5</td>\n",
       "      <td>12.20</td>\n",
       "      <td>80.46</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>28.94</td>\n",
       "      <td>9.37</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  ... station_min_temp_c  station_precip_mm  total_cases\n",
       "0   sj  1990          18  ...               20.0               16.0            4\n",
       "1   sj  1990          19  ...               22.2                8.6            5\n",
       "2   sj  1990          20  ...               22.8               41.4            4\n",
       "3   sj  1990          21  ...               23.3                4.0            3\n",
       "4   sj  1990          22  ...               23.9                5.8            6\n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tzpKqb7aDu-h"
   },
   "outputs": [],
   "source": [
    "train=train.interpolate(kind='linear',limit_direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CjjqAV1r1DjI"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data,norm_cols=[],scale_cols=[],train_scale=None):\n",
    "  df=data.copy()\n",
    "  if train_scale is None:\n",
    "    train_scale=data\n",
    "  if norm_cols:\n",
    "    df[norm_cols]=StandardScaler().fit(train_scale[norm_cols]).transform(df[norm_cols])\n",
    "  if scale_cols:\n",
    "    df[scale_cols]=MinMaxScaler(feature_range=(0,1)).fit(train_scale[scale_cols]).transform(df[scale_cols])\n",
    "  return df\n",
    "def generate_multivariate_data(data,history_size=12,target_size=1,train_fraction=1,target_col=-1):\n",
    "  datasets=[]\n",
    "  labels=data[:,target_col]\n",
    "  data=data[:,:target_col]\n",
    "  data_size=len(data)\n",
    "  start_idx=history_size\n",
    "  train_to_idx=int(data_size*train_fraction) if train_fraction!=1 else data_size-target_size\n",
    "  val_idx=train_to_idx+history_size\n",
    "  end_idx=data_size-target_size\n",
    "  indexes=[(start_idx,train_to_idx)]\n",
    "  if train_fraction!=1:\n",
    "    indexes.append((val_idx,end_idx))\n",
    "  for start,end in indexes:\n",
    "    d=[]\n",
    "    y=[]\n",
    "    for i in range(start,end):\n",
    "      indices=range(i-history_size,i)\n",
    "      d.append(data[indices])\n",
    "      y.append(labels[i-1])\n",
    "    datasets.append((np.array(d),np.array(y)))\n",
    "  return datasets\n",
    "def generate_lstm_data(dataframe,cols=[],scale_cols=[],norm_cols=[],history_size=12,target_size=1,train_fraction=1,target_col=-1,prepend_file=None,train_scale=None):\n",
    "  df=dataframe[cols].copy()\n",
    "  if \"total_cases\" not in df.columns:\n",
    "    df[\"total_cases\"]=np.zeros((len(df),1))\n",
    "  if prepend_file is not None:\n",
    "    prepend=prepend_file[cols].copy()\n",
    "  datasets=[]\n",
    "  for city in [\"sj\",\"iq\"]:\n",
    "    city_df=df[df['city']==city]\n",
    "    if prepend_file is not None:\n",
    "      city_df=prepend[prepend['city']==city].iloc[-(history_size+1):].append(city_df,ignore_index=True)\n",
    "    train_scale=city_df.copy()\n",
    "    city_df.index=city_df['week_start_date']\n",
    "    city_df=preprocess_data(city_df[norm_cols+scale_cols+[\"total_cases\"]],norm_cols=norm_cols,scale_cols=scale_cols,\n",
    "                            train_scale=train_scale)\n",
    "    datasets.append(city_df.values)\n",
    "  return list(map(lambda x: generate_multivariate_data(x,history_size=history_size,train_fraction=train_fraction),datasets))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8Fbahldm2QA5"
   },
   "outputs": [],
   "source": [
    "new_iq_norm = [\n",
    "                'reanalysis_tdtr_k',\n",
    "                'reanalysis_precip_amt_kg_per_m2',\n",
    "                'reanalysis_relative_humidity_percent',\n",
    "                'station_avg_temp_c',\n",
    "                'station_min_temp_c',\n",
    "                'reanalysis_dew_point_temp_k',\n",
    "                'reanalysis_specific_humidity_g_per_kg',\n",
    "                'reanalysis_min_air_temp_k'\n",
    "]\n",
    "new_iq_scale = [\n",
    "                   'year',\n",
    "]\n",
    "\n",
    "new_sj_norm = [\n",
    "                'precipitation_amt_mm',\n",
    "                'reanalysis_air_temp_k',\n",
    "                'reanalysis_avg_temp_k',\n",
    "                'reanalysis_max_air_temp_k',\n",
    "                'reanalysis_min_air_temp_k',\n",
    "                'reanalysis_precip_amt_kg_per_m2',\n",
    "                'reanalysis_relative_humidity_percent',\n",
    "                'reanalysis_sat_precip_amt_mm',\n",
    "                'station_avg_temp_c',\n",
    "                'station_max_temp_c',\n",
    "                'station_min_temp_c',\n",
    "                \n",
    "]\n",
    "new_sj_scale = [\n",
    "                   'weekofyear'\n",
    "                \n",
    "]\n",
    "sj_cols=new_sj_norm+new_sj_scale+[\"total_cases\",\"city\",\"week_start_date\"]\n",
    "iq_cols=new_iq_norm+new_iq_scale+[\"total_cases\",\"city\",\"week_start_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "LEW_ANZICfvA"
   },
   "outputs": [],
   "source": [
    "sj_datasets=generate_lstm_data(train,cols=sj_cols,scale_cols=new_sj_scale,norm_cols=new_sj_norm,history_size=32,prepend_file=train)\n",
    "iq_datasets=generate_lstm_data(train,cols=iq_cols,scale_cols=new_iq_scale,norm_cols=new_iq_norm,history_size=32,prepend_file=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "48y_Zd51Cw91"
   },
   "outputs": [],
   "source": [
    "(sj_train_x, sj_train_y) = sj_datasets[0][0]\n",
    "(iq_train_x, iq_train_y) = iq_datasets[1][0]\n",
    "sj_train_x = sj_train_x.reshape(sj_train_x.shape[0], sj_train_x.shape[1] * sj_train_x.shape[2])\n",
    "iq_train_x = iq_train_x.reshape(iq_train_x.shape[0], iq_train_x.shape[1] * iq_train_x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAQNjcqODPqP",
    "outputId": "20084edd-f567-4bc0-b430-db874ee434f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 384)\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer = None, nodes=256, input_shape=sj_train_x.shape[-1]):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=input_shape),\n",
    "    tf.keras.layers.Dense(nodes, activation='selu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(nodes/2, activation='selu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  if not optimizer:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "\n",
    "  model.compile(loss='mae',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model\n",
    "\n",
    "print(sj_train_x.shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFObONr8DXRF",
    "outputId": "0fb7b045-307b-4a5f-c529-9d083f2c0f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/8\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 23.3829 - mae: 23.3829 - mse: 2562.6882\n",
      "Epoch 2/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.2421 - mae: 20.2421 - mse: 2109.4387\n",
      "Epoch 3/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.6792 - mae: 19.6792 - mse: 2020.0983\n",
      "Epoch 4/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0406 - mae: 19.0406 - mse: 1871.1874\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 5/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.3503 - mae: 18.3503 - mse: 1744.0792\n",
      "Epoch 6/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.7253 - mae: 17.7253 - mse: 1611.4338\n",
      "Epoch 7/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.1373 - mae: 17.1373 - mse: 1505.7103\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "Epoch 8/8\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.1249 - mae: 17.1249 - mse: 1519.7767\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 8\n",
    "BUFFER_SIZE=500\n",
    "BATCH_SIZE=16\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"mae\", factor=0.8, patience=3, min_lr=1e-6, verbose=1,\n",
    "                                                     mode=\"max\")\n",
    "\n",
    "train_sj_data_single = tf.data.Dataset.from_tensor_slices((sj_train_x, sj_train_y))\n",
    "train_sj_data_single = train_sj_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.01, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "sj_model = build_model(optimizer=opt, nodes=80)\n",
    "history = sj_model.fit(\n",
    "    train_sj_data_single,\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=EVALUATION_INTERVAL,\n",
    "    verbose=1,\n",
    "    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LROxmP77DfWE",
    "outputId": "ec12e929-a4ba-459a-cf8f-ab633cc2827f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/22\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 7.1258 - mae: 7.1258 - mse: 154.0402\n",
      "Epoch 2/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.4578 - mae: 6.4578 - mse: 137.0000\n",
      "Epoch 3/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.1435 - mae: 6.1435 - mse: 127.0499\n",
      "Epoch 4/22\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.9743 - mae: 5.9743 - mse: 123.8367\n",
      "Epoch 5/22\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.8348 - mae: 5.8348 - mse: 121.4218\n",
      "Epoch 6/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.6926 - mae: 5.6926 - mse: 116.2898\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 7/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.5946 - mae: 5.5946 - mse: 113.8287\n",
      "Epoch 8/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.6528 - mae: 5.6528 - mse: 120.5436\n",
      "Epoch 9/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.4584 - mae: 5.4584 - mse: 111.6117\n",
      "Epoch 10/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.3821 - mae: 5.3821 - mse: 110.3253\n",
      "Epoch 11/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.3196 - mae: 5.3196 - mse: 108.6491\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 12/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.2116 - mae: 5.2116 - mse: 106.7451\n",
      "Epoch 13/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.1701 - mae: 5.1701 - mse: 106.2386\n",
      "Epoch 14/22\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.1396 - mae: 5.1396 - mse: 104.8610\n",
      "Epoch 15/22\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9688 - mae: 4.9688 - mse: 99.1559\n",
      "Epoch 16/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.9366 - mae: 4.9366 - mse: 99.0005\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 17/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.8343 - mae: 4.8343 - mse: 97.2586\n",
      "Epoch 18/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.8090 - mae: 4.8090 - mse: 94.2700\n",
      "Epoch 19/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.7285 - mae: 4.7285 - mse: 93.2189\n",
      "Epoch 20/22\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.6805 - mae: 4.6805 - mse: 93.3160\n",
      "Epoch 21/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.6890 - mae: 4.6890 - mse: 92.0311\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 22/22\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.5755 - mae: 4.5755 - mse: 90.6510\n"
     ]
    }
   ],
   "source": [
    "train_iq_data_single = tf.data.Dataset.from_tensor_slices((iq_train_x, iq_train_y))\n",
    "train_iq_data_single = train_iq_data_single.cache().shuffle(500).batch(16).repeat()\n",
    "\n",
    "EPOCHS = 22\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.9999, amsgrad=False)\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "iq_model = build_model(optimizer=opt, nodes=80, input_shape=iq_train_x.shape[-1])\n",
    "train_iq_data_single = tf.data.Dataset.from_tensor_slices((iq_train_x, iq_train_y))\n",
    "train_iq_data_single = train_iq_data_single.cache().batch(BATCH_SIZE).repeat()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"mae\", factor=0.8, patience=5, min_lr=1e-6, verbose=1,\n",
    "                                                     mode=\"max\")\n",
    "history = iq_model.fit(\n",
    "    train_iq_data_single,\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=EVALUATION_INTERVAL,\n",
    "    verbose=1,\n",
    "    callbacks=[ reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "NsoAv__tGjg8"
   },
   "outputs": [],
   "source": [
    "test_sj_cols=['precipitation_amt_mm',\n",
    " 'reanalysis_air_temp_k',\n",
    " 'reanalysis_avg_temp_k',\n",
    " 'reanalysis_max_air_temp_k',\n",
    " 'reanalysis_min_air_temp_k',\n",
    " 'reanalysis_precip_amt_kg_per_m2',\n",
    " 'reanalysis_relative_humidity_percent',\n",
    " 'reanalysis_sat_precip_amt_mm',\n",
    " 'station_avg_temp_c',\n",
    " 'station_max_temp_c',\n",
    " 'station_min_temp_c',\n",
    " 'weekofyear',\n",
    " 'city',\n",
    " 'week_start_date']\n",
    "test_iq_cols=['reanalysis_tdtr_k', 'reanalysis_precip_amt_kg_per_m2', 'reanalysis_relative_humidity_percent', 'station_avg_temp_c', 'station_min_temp_c', 'reanalysis_dew_point_temp_k', 'reanalysis_specific_humidity_g_per_kg', 'reanalysis_min_air_temp_k', 'year', 'city', 'week_start_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRqGCB3tFQRO",
    "outputId": "d8368e23-eb6c-4018-de0e-a91a0aaf05f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv(\"/content/dengue_features_test.csv\")\n",
    "test=test.interpolate(kind='linear',limit_direction='forward')\n",
    "sj_test=generate_lstm_data(test,cols=test_sj_cols,scale_cols=new_sj_scale,norm_cols=new_sj_norm,history_size=32,prepend_file=train)\n",
    "iq_test=generate_lstm_data(test,cols=test_iq_cols,scale_cols=new_iq_scale,norm_cols=new_iq_norm,history_size=32,prepend_file=train)\n",
    "(sj_test_x, sj_test_y), = sj_test[0]\n",
    "(iq_test_x, iq_test_y), = iq_test[1]\n",
    "sj_test_x = sj_test_x.reshape(sj_test_x.shape[0], sj_test_x.shape[1] * sj_test_x.shape[2])\n",
    "iq_test_x = iq_test_x.reshape(iq_test_x.shape[0], iq_test_x.shape[1] * iq_test_x.shape[2])\n",
    "sj_test_set = tf.data.Dataset.from_tensor_slices((sj_test_x, sj_test_y)).batch(len(sj_test_y))\n",
    "\n",
    "sj_pred = []\n",
    "for x, y in sj_test_set.take(1):\n",
    "    predictions = sj_model.predict(x)\n",
    "    sj_pred = predictions.flatten()\n",
    "    print(len(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2j7n1G4GVhv",
    "outputId": "f2af628f-8cad-4a66-81f5-a006a364263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "iq_test_set = tf.data.Dataset.from_tensor_slices((iq_test_x, iq_test_y)).batch(len(iq_test_y))\n",
    "iq_pred = []\n",
    "for x, y in iq_test_set.take(1):\n",
    "    predictions = iq_model.predict(x)\n",
    "    iq_pred = predictions.flatten()\n",
    "    print(len(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "9aW-2T7aI5Qa"
   },
   "outputs": [],
   "source": [
    "preds = np.concatenate((sj_pred, iq_pred), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "7hXii05BI_tT"
   },
   "outputs": [],
   "source": [
    "t=pd.read_csv(\"/content/dengue_features_test.csv\")\n",
    "t['total_cases']=preds\n",
    "t['total_cases']=t['total_cases'].apply(lambda x: int(x) if x>0 else 0)\n",
    "t[['city','year','weekofyear','total_cases']].to_csv(\"submission.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled75.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
